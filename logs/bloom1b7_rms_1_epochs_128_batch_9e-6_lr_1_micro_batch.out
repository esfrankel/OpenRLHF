[2024-07-01 16:50:06,105] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-07-01 16:50:06,106] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-07-01 16:50:06,131] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-07-01 16:50:27,646] [WARNING] [runner.py:202:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
Detected CUDA_VISIBLE_DEVICES=0: setting --include=localhost:0
[2024-07-01 16:50:27,652] [INFO] [runner.py:568:main] cmd = /gscratch/sewoong/ericsf/miniconda3/envs/openrlhf/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMF19 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None ppi_scripts/train_rm.py --save_path ./ckpt/bloom1b7_rms_1_epochs_128_batch_9e-6_lr_1_micro_batch --save_steps 1000 --logging_steps 1 --eval_steps 5000 --train_batch_size 128 --micro_train_batch_size 1 --pretrain OpenLLMAI/Llama-2-7b-sft-model-ocra-500k --bf16 --max_epochs 1 --max_len 2048 --zero_stage 3 --learning_rate 9e-6 --dataset --dataset_probs 1.0 --gradient_checkpointing --use_wandb True --wandb_org esfrankel-uw --wandb_group train_rm_bloom1b7 --wandb_project openrlhf_train_rm_ppi
[2024-07-01 16:50:27,655] [WARNING] [runner.py:202:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
[2024-07-01 16:50:27,657] [WARNING] [runner.py:202:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
Detected CUDA_VISIBLE_DEVICES=0: setting --include=localhost:0
[2024-07-01 16:50:27,682] [INFO] [runner.py:568:main] cmd = /gscratch/sewoong/ericsf/miniconda3/envs/openrlhf/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMF19 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None ppi_scripts/train_rm.py --save_path ./ckpt/bloom1b7_rms_1_epochs_128_batch_9e-6_lr_1_micro_batch --save_steps 1000 --logging_steps 1 --eval_steps 5000 --train_batch_size 128 --micro_train_batch_size 1 --pretrain OpenLLMAI/Llama-2-7b-sft-model-ocra-500k --bf16 --max_epochs 1 --max_len 2048 --zero_stage 3 --learning_rate 9e-6 --dataset argilla/ultrafeedback-binarized-preferences-cleaned, --dataset_probs 1.0,1.0 --gradient_checkpointing --use_wandb True --wandb_org esfrankel-uw --wandb_group train_rm_bloom1b7 --wandb_project openrlhf_train_rm_ppi
Detected CUDA_VISIBLE_DEVICES=0: setting --include=localhost:0
[2024-07-01 16:50:27,670] [INFO] [runner.py:568:main] cmd = /gscratch/sewoong/ericsf/miniconda3/envs/openrlhf/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMF19 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None ppi_scripts/train_rm.py --save_path ./ckpt/bloom1b7_rms_1_epochs_128_batch_9e-6_lr_1_micro_batch --save_steps 1000 --logging_steps 1 --eval_steps 5000 --train_batch_size 128 --micro_train_batch_size 1 --pretrain OpenLLMAI/Llama-2-7b-sft-model-ocra-500k --bf16 --max_epochs 1 --max_len 2048 --zero_stage 3 --learning_rate 9e-6 --dataset argilla/ultrafeedback-binarized-preferences-cleaned --dataset_probs 1.0 --gradient_checkpointing --use_wandb True --wandb_org esfrankel-uw --wandb_group train_rm_bloom1b7 --wandb_project openrlhf_train_rm_ppi
[2024-07-01 16:50:29,718] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-07-01 16:50:29,862] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-07-01 16:50:30,439] [INFO] [launch.py:145:main] WORLD INFO DICT: {'localhost': [0]}
[2024-07-01 16:50:30,444] [INFO] [launch.py:151:main] nnodes=1, num_local_procs=1, node_rank=0
[2024-07-01 16:50:30,444] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0]})
[2024-07-01 16:50:30,444] [INFO] [launch.py:163:main] dist_world_size=1
[2024-07-01 16:50:30,444] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0
[2024-07-01 16:50:30,445] [INFO] [launch.py:253:main] process 15913 spawned with command: ['/gscratch/sewoong/ericsf/miniconda3/envs/openrlhf/bin/python', '-u', 'ppi_scripts/train_rm.py', '--local_rank=0', '--save_path', './ckpt/bloom1b7_rms_1_epochs_128_batch_9e-6_lr_1_micro_batch', '--save_steps', '1000', '--logging_steps', '1', '--eval_steps', '5000', '--train_batch_size', '128', '--micro_train_batch_size', '1', '--pretrain', 'OpenLLMAI/Llama-2-7b-sft-model-ocra-500k', '--bf16', '--max_epochs', '1', '--max_len', '2048', '--zero_stage', '3', '--learning_rate', '9e-6', '--dataset', '--dataset_probs', '1.0', '--gradient_checkpointing', '--use_wandb', 'True', '--wandb_org', 'esfrankel-uw', '--wandb_group', 'train_rm_bloom1b7', '--wandb_project', 'openrlhf_train_rm_ppi']
[2024-07-01 16:50:30,562] [INFO] [launch.py:145:main] WORLD INFO DICT: {'localhost': [0]}
[2024-07-01 16:50:30,573] [INFO] [launch.py:151:main] nnodes=1, num_local_procs=1, node_rank=0
[2024-07-01 16:50:30,573] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0]})
[2024-07-01 16:50:30,573] [INFO] [launch.py:163:main] dist_world_size=1
[2024-07-01 16:50:30,573] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0
[2024-07-01 16:50:30,574] [INFO] [launch.py:253:main] process 26954 spawned with command: ['/gscratch/sewoong/ericsf/miniconda3/envs/openrlhf/bin/python', '-u', 'ppi_scripts/train_rm.py', '--local_rank=0', '--save_path', './ckpt/bloom1b7_rms_1_epochs_128_batch_9e-6_lr_1_micro_batch', '--save_steps', '1000', '--logging_steps', '1', '--eval_steps', '5000', '--train_batch_size', '128', '--micro_train_batch_size', '1', '--pretrain', 'OpenLLMAI/Llama-2-7b-sft-model-ocra-500k', '--bf16', '--max_epochs', '1', '--max_len', '2048', '--zero_stage', '3', '--learning_rate', '9e-6', '--dataset', 'argilla/ultrafeedback-binarized-preferences-cleaned', '--dataset_probs', '1.0', '--gradient_checkpointing', '--use_wandb', 'True', '--wandb_org', 'esfrankel-uw', '--wandb_group', 'train_rm_bloom1b7', '--wandb_project', 'openrlhf_train_rm_ppi']
[2024-07-01 16:50:32,081] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-07-01 16:50:33,266] [INFO] [launch.py:145:main] WORLD INFO DICT: {'localhost': [0]}
[2024-07-01 16:50:33,266] [INFO] [launch.py:151:main] nnodes=1, num_local_procs=1, node_rank=0
[2024-07-01 16:50:33,266] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0]})
[2024-07-01 16:50:33,266] [INFO] [launch.py:163:main] dist_world_size=1
[2024-07-01 16:50:33,266] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0
[2024-07-01 16:50:33,267] [INFO] [launch.py:253:main] process 81512 spawned with command: ['/gscratch/sewoong/ericsf/miniconda3/envs/openrlhf/bin/python', '-u', 'ppi_scripts/train_rm.py', '--local_rank=0', '--save_path', './ckpt/bloom1b7_rms_1_epochs_128_batch_9e-6_lr_1_micro_batch', '--save_steps', '1000', '--logging_steps', '1', '--eval_steps', '5000', '--train_batch_size', '128', '--micro_train_batch_size', '1', '--pretrain', 'OpenLLMAI/Llama-2-7b-sft-model-ocra-500k', '--bf16', '--max_epochs', '1', '--max_len', '2048', '--zero_stage', '3', '--learning_rate', '9e-6', '--dataset', 'argilla/ultrafeedback-binarized-preferences-cleaned,', '--dataset_probs', '1.0,1.0', '--gradient_checkpointing', '--use_wandb', 'True', '--wandb_org', 'esfrankel-uw', '--wandb_group', 'train_rm_bloom1b7', '--wandb_project', 'openrlhf_train_rm_ppi']
[2024-07-01 16:50:46,318] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-07-01 16:50:46,344] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-07-01 16:50:46,520] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-07-01 16:50:52,830] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-07-01 16:50:52,831] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-07-01 16:50:52,833] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2024-07-01 16:50:52,896] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2024-07-01 16:50:55,290] [INFO] [launch.py:316:sigkill_handler] Killing subprocess 81512
[2024-07-01 16:50:55,290] [ERROR] [launch.py:322:sigkill_handler] ['/gscratch/sewoong/ericsf/miniconda3/envs/openrlhf/bin/python', '-u', 'ppi_scripts/train_rm.py', '--local_rank=0', '--save_path', './ckpt/bloom1b7_rms_1_epochs_128_batch_9e-6_lr_1_micro_batch', '--save_steps', '1000', '--logging_steps', '1', '--eval_steps', '5000', '--train_batch_size', '128', '--micro_train_batch_size', '1', '--pretrain', 'OpenLLMAI/Llama-2-7b-sft-model-ocra-500k', '--bf16', '--max_epochs', '1', '--max_len', '2048', '--zero_stage', '3', '--learning_rate', '9e-6', '--dataset', 'argilla/ultrafeedback-binarized-preferences-cleaned,', '--dataset_probs', '1.0,1.0', '--gradient_checkpointing', '--use_wandb', 'True', '--wandb_org', 'esfrankel-uw', '--wandb_group', 'train_rm_bloom1b7', '--wandb_project', 'openrlhf_train_rm_ppi'] exits with return code = 1
[2024-07-01 16:51:01,476] [INFO] [launch.py:316:sigkill_handler] Killing subprocess 15913
[2024-07-01 16:51:01,479] [ERROR] [launch.py:322:sigkill_handler] ['/gscratch/sewoong/ericsf/miniconda3/envs/openrlhf/bin/python', '-u', 'ppi_scripts/train_rm.py', '--local_rank=0', '--save_path', './ckpt/bloom1b7_rms_1_epochs_128_batch_9e-6_lr_1_micro_batch', '--save_steps', '1000', '--logging_steps', '1', '--eval_steps', '5000', '--train_batch_size', '128', '--micro_train_batch_size', '1', '--pretrain', 'OpenLLMAI/Llama-2-7b-sft-model-ocra-500k', '--bf16', '--max_epochs', '1', '--max_len', '2048', '--zero_stage', '3', '--learning_rate', '9e-6', '--dataset', '--dataset_probs', '1.0', '--gradient_checkpointing', '--use_wandb', 'True', '--wandb_org', 'esfrankel-uw', '--wandb_group', 'train_rm_bloom1b7', '--wandb_project', 'openrlhf_train_rm_ppi'] exits with return code = 2
[2024-07-01 16:51:11,618] [INFO] [launch.py:316:sigkill_handler] Killing subprocess 26954
[2024-07-01 16:51:11,620] [ERROR] [launch.py:322:sigkill_handler] ['/gscratch/sewoong/ericsf/miniconda3/envs/openrlhf/bin/python', '-u', 'ppi_scripts/train_rm.py', '--local_rank=0', '--save_path', './ckpt/bloom1b7_rms_1_epochs_128_batch_9e-6_lr_1_micro_batch', '--save_steps', '1000', '--logging_steps', '1', '--eval_steps', '5000', '--train_batch_size', '128', '--micro_train_batch_size', '1', '--pretrain', 'OpenLLMAI/Llama-2-7b-sft-model-ocra-500k', '--bf16', '--max_epochs', '1', '--max_len', '2048', '--zero_stage', '3', '--learning_rate', '9e-6', '--dataset', 'argilla/ultrafeedback-binarized-preferences-cleaned', '--dataset_probs', '1.0', '--gradient_checkpointing', '--use_wandb', 'True', '--wandb_org', 'esfrankel-uw', '--wandb_group', 'train_rm_bloom1b7', '--wandb_project', 'openrlhf_train_rm_ppi'] exits with return code = 1
